{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c56dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from astropy import table\n",
    "from astroquery.jplhorizons import Horizons\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pympler.process import _ProcessMemoryInfoProc\n",
    "\n",
    "from lhorizon import LHorizon\n",
    "from lhorizon.tests.utilz import MockResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b93654",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab cached http responses from JPL Horizons\n",
    "def make_mock_response(cached_response_fn):\n",
    "    def respond_mockingly(*_, **__):\n",
    "        with open(cached_response_fn, 'rb') as mock_response_stream:\n",
    "            mock_response_bytes = mock_response_stream.read()\n",
    "        return MockResponse(content=mock_response_bytes)\n",
    "    return respond_mockingly\n",
    "\n",
    "\n",
    "cached_responses = {\n",
    "    r.name.split(\"_\")[-1]: r\n",
    "    for r in Path('samples/').iterdir()\n",
    "    if 'response' in r.name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd90ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert these responses into sets of \n",
    "# jplhorizons.Horizons and lhorizon.LHorizon objects\n",
    "mocked_horizons, mocked_lhorizons = [], []\n",
    "for response_ix in sorted(cached_responses.keys()):\n",
    "    mock_response = make_mock_response(cached_responses[response_ix])\n",
    "    horizon = Horizons()\n",
    "    horizon.cache_location = None\n",
    "    horizon.ephemerides_async = mock_response\n",
    "    horizon.query_type='ephemerides'\n",
    "    mocked_horizons.append(horizon)\n",
    "    lhorizon = LHorizon()\n",
    "    lhorizon.response = mock_response()\n",
    "    mocked_lhorizons.append(lhorizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989b7b0",
   "metadata": {},
   "source": [
    "### lhorizon.LHorizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Jupyter 'magic' that checks execution time of the cell\n",
    "\n",
    "# crude indicator of current real memory usage of the process\n",
    "s_mem = _ProcessMemoryInfoProc().rss \n",
    "lhorizon_dataframes = [\n",
    "    l.dataframe() for l in mocked_lhorizons\n",
    "]\n",
    "full_lhorizon_table = pd.concat(lhorizon_dataframes)\n",
    "# check real memory again after objects have been initialized\n",
    "e_mem = _ProcessMemoryInfoProc().rss\n",
    "print(f\"{round((e_mem - s_mem) / 1024 ** 2)} MB used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32d4e3",
   "metadata": {},
   "source": [
    "### jplhorizons.Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Jupyter 'magic' that checks execution time of the cell\n",
    "\n",
    "# crude indicator of current real memory usage of the process\n",
    "s_mem = _ProcessMemoryInfoProc().rss\n",
    "horizons_tables = [\n",
    "    horizon.ephemerides() for horizon in mocked_horizons\n",
    "]\n",
    "full_horizon_table = table.vstack(horizons_tables)\n",
    "# check real memory again after objects have been initialized\n",
    "e_mem = _ProcessMemoryInfoProc().rss\n",
    "print(f\"{round((e_mem - s_mem) / 1024 ** 2)} MB used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80361bdd",
   "metadata": {},
   "source": [
    "### consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we get the same values for time, RA, and DEC from both Horizons and LHorizon\n",
    "# for the (mocked) Horizons service web response?\n",
    "horizon_array = full_horizon_table.to_pandas().values\n",
    "lhorizon_array = full_lhorizon_table.values\n",
    "# timestamps\n",
    "assert np.all(lhorizon_array[:, 0] == horizon_array[:, 1])\n",
    "# right ascension\n",
    "assert np.all(lhorizon_array[:, 5] == horizon_array[:, 6])\n",
    "# declination\n",
    "assert np.all(lhorizon_array[:, 4] == horizon_array[:, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea54223",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**notes**\n",
    "\n",
    "* Generally, `lhorizon` will perform the above operations about 10x as fast as `jplhorizons` in about 25-50% as much memory. However, this may vary widely depending on the environment. Also, astropy `Table` objects are difficult to introspect directly, and  `_ProcessMemoryInfoProc().rss`, which returns resident set size of the containing process, may be unreliable depending on how your particular environment allocates memory to Notebook processes. For a clearer look at this, run the memory_profile* scripts in this directory (note that in some environments, these functions may run quite slowly under this profiler; don't be in a hurry).\n",
    "* `lhorizon` is _often_ faster than `jplhorizons` at fetching data from Horizons, and the bulk query helpers in `lhorizon.handlers` can also greatly expedite some queries. However, there is no consistent way to compare these steps because Horizons has so much serverside variability in response time, which is why we use cached/mocked responses in these examples. \n",
    "* the `horizon.cache_location=None` statement disables `astroquery` default caching. `astroquery` caches many queries as .pickle files, (by default in an .astroquery subdirectory of the user's home directory). Otherwise, if this benchmark is run multiple times in the same environment, even across sessions, `jplhorizons` will load an `astropy.Table` object from a pickle file rather than querying and parsing Horizons' outputs. `lhorizon` does not, and does not plan to, offer this type of automated caching, due to concerns about cross-environment stability, data freshness, transparency of local storage usage, and so on. If you would like to repeatedly run identical queries against Horizons and do not wish to make intermediate data products, `jplhorizons` may be superior for your use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
