{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c56dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from astropy import table\n",
    "from astroquery.jplhorizons import Horizons\n",
    "import pandas as pd\n",
    "from pympler.process import _ProcessMemoryInfoProc\n",
    "\n",
    "from lhorizon import LHorizon\n",
    "from lhorizon.tests.utilz import MockResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56ede5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`lhorizon` is a strongly divergent fork of `astroquery.jplhorizons`.\n",
    "When compared to `jplhorizons`, it offers:\n",
    "* fuller coverage of many Horizons API areas\n",
    "* a wide array of helper functions\n",
    "* an optional targeting module that provides SPICE integration and bodycentric coordinate transformations\n",
    "* a more consistent, modular, and extensible interface, and\n",
    "* increased performance.\n",
    "\n",
    "This notebook illustrates several performance differences between `jplhorizons` and `lhorizon`.\n",
    "\n",
    "[Extra files not distributed with this repository are necessary to use this notebook](https://drive.google.com/file/d/1o3R7EEZt06mbqhh8sAoH6TgFsIcvAIov/)\n",
    "Please grab and decompress this file, creating a directory named 'samples', and place that 'samples' directory in this\n",
    "directory ('benchmark')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7684c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab cached http responses from JPL Horizons\n",
    "def make_mock_response(cached_response_fn):\n",
    "    def respond_mockingly(*_, **__):\n",
    "        with open(cached_response_fn, 'rb') as mock_response_stream:\n",
    "            mock_response_bytes = mock_response_stream.read()\n",
    "        return MockResponse(content=mock_response_bytes)\n",
    "    return respond_mockingly\n",
    "\n",
    "\n",
    "cached_responses = {\n",
    "    r.name.split(\"_\")[-1]: r\n",
    "    for r in Path('samples/').iterdir()\n",
    "    if 'response' in r.name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd90ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert these responses into jplhorizons.Horizons and lhorizon.LHorizon objects\n",
    "mocked_horizons, mocked_lhorizons = [], []\n",
    "for response_ix in sorted(cached_responses.keys()):\n",
    "    mock_response = make_mock_response(cached_responses[response_ix])\n",
    "    horizon = Horizons()\n",
    "    horizon.cache_location = None\n",
    "    horizon.ephemerides_async = mock_response\n",
    "    horizon.query_type='ephemerides'\n",
    "    mocked_horizons.append(horizon)\n",
    "    lhorizon = LHorizon()\n",
    "    lhorizon.response = mock_response()\n",
    "    mocked_lhorizons.append(lhorizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e451d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 MB used\n",
      "CPU times: user 1.98 s, sys: 290 ms, total: 2.27 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s_mem = _ProcessMemoryInfoProc().rss\n",
    "lhorizon_dataframes = [\n",
    "    l.dataframe() for l in mocked_lhorizons\n",
    "]\n",
    "full_lhorizon_table = pd.concat(lhorizon_dataframes)\n",
    "e_mem = _ProcessMemoryInfoProc().rss\n",
    "print(f\"{round((e_mem - s_mem) / 1024 ** 2)} MB used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49b8e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611 MB used\n",
      "CPU times: user 23 s, sys: 197 ms, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compare parser speed and (crudely) memory usage of jplhorizons and lhorizon\n",
    "s_mem = _ProcessMemoryInfoProc().rss\n",
    "horizons_tables = [\n",
    "    horizon.ephemerides() for horizon in mocked_horizons\n",
    "]\n",
    "full_horizon_table = table.vstack(horizons_tables)\n",
    "e_mem = _ProcessMemoryInfoProc().rss\n",
    "print(f\"{round((e_mem - s_mem) / 1024 ** 2)} MB used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea54223",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**notes**\n",
    "\n",
    "* Generally, `lhorizon` will perform the above operations about 10x as fast as `jplhorizons` in about 50% as much memory. However, this may vary widely depending on the environment. Also, astropy `Table` objects are difficult to introspect directly, and  `_ProcessMemoryInfoProc().rss`, which returns resident set size of the containing process, may be unreliable depending on how your particular environment allocates memory to Notebook processes. For a clearer look at this, run the memory_profile* scripts in this directory (note that in some environments, these functions may run quite slowly under this profiler; don't be in a hurry).\n",
    "* `lhorizon` is _often_ faster than `jplhorizons` at fetching data from Horizons, and the bulk query helpers in `lhorizon.handlers` can also greatly expedite some queries. However, there is no consistent way to compare these steps because Horizons has so much serverside variability in response time, which is why we use cached/mocked responses in these examples. \n",
    "* the `horizon.query_type='ephemerides'` statement disables `astroquery` default caching. `astroquery` caches many queries as .pickle files, (by default in the user's home directory). Otherwise, if this benchmark is run multiple times in the same environment, even across sessions, `jplhorizons` will load an `astropy.Table` object from a pickle file rather than querying and parsing Horizons' outputs. `lhorizon` does not, and does not plan to, offer this type of automated caching, due to concerns about cross-environment stability, data freshness, transparency of local storage usage, and so on. If you would like to repeatedly run identical queries against Horizons and do not wish to make intermediate data products, `jplhorizons` may be superior for your use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
